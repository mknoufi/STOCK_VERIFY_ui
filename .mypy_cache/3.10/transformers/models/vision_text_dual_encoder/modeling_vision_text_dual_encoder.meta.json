{"data_mtime":1767697672,"dep_hashes":["3c619d4ddc3390e1a29106830e39c62d55f0dca5","85ebfca4af7b3e4ab4474665bea6a94ae73e5f41","d517fee015d904d1a2f5426f2b0a6d06f108a9e9","3e82ae328d4e43c165ee7fd2bc41e556532e47f0","c371c8262ef0e71d2a03a31e0390e4ca470efa28","b92ef02a3502e0836c1e49bc5d424600f75b9d2b","242bee20eab142e93fc805ed9c263e8c0d6d43ff","91a68fec0bcb24012e59ff582a87cf95b5a12c37","dad6fa599cd9e8c9f7f32d1acf1502833d75c1b0","f1d0c295f4a87de9cf2889f4af2a6fc762164dc7","6ddb6f13b3590b1708d05529fb99637945ca75dc","d59d48f5a0e384aec2eeb1945c489cd3a7957090","ddf753d7b8e8c270291880218f90ed2b62a277ee","212d34d9e06c4cc566a576d3c3cffa805e92d065","2949e71b8686931200359909a6eb4b0135b73400","c178cc53cb428a2c6ebc6ba780676a177a6f90e9","65b0186e87797cf1503e549c8c31b066d27ab110","00dba6487f573a7796c1c29727752f4f7fff178f","8e39d1f1f7427b3370800f29ba4be00124232b4a","a0cbcaec349b176731b014bdff5162aa1fa225b2","4ce56c5a0032848d80757f7262f06b1bf31703a2","4a2a0d8b8b5c9679e07f99bf8b7fbe5c679cbd27","06b37fe2114cfc23f4f086fac54735ae34ea4de3","a19a8adfded4db26b6ccd0205c2327557d917d29","861b6a0e2354aceed94cf0b64c4741d33dbe9caa","7c4d671403f6b0bb737ea27b30e867feace0fc8d","b569a80ea63437930e85205a7dca0f1020aeaa4e","3fbbe6ac3dbdcea502f034adbbc9e68a6bcb2573","435799564b770b39f80bb589cfe0f47cfe8aa4c2","18ed1e4edd2f93219492500989b33e2e5a7ae227"],"dep_lines":[25,26,27,28,24,24,20,22,23,24,17,19,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,5,5,5,10,10,10,5,5,5,5,10,5,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30],"dependencies":["transformers.models.auto.configuration_auto","transformers.models.auto.modeling_auto","transformers.models.clip.modeling_clip","transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder","transformers.utils.auto_docstring","transformers.utils.logging","torch.nn","transformers.modeling_outputs","transformers.modeling_utils","transformers.utils","typing","torch","builtins","abc","collections","logging","torch._C","torch._C._VariableFunctions","torch._prims_common","torch._tensor","torch.nn.modules.linear","torch.nn.modules.module","torch.nn.parameter","transformers.configuration_utils","transformers.integrations.peft","transformers.models.auto.auto_factory","transformers.models.clip.configuration_clip","transformers.utils.generic","transformers.utils.hub","types"],"error_lines":[],"hash":"c0705d436207ca6cc08a92653519c1954c3b169e","id":"transformers.models.vision_text_dual_encoder.modeling_vision_text_dual_encoder","ignore_all":true,"interface_hash":"27ac9974ef463922ca5e4ee01a36255625776423","mtime":1766134131,"options":{"other_options":"631b02669c43f539d4be2012709fe971181cf59a","platform":"darwin"},"path":"/Users/noufi1/Library/Python/3.9/lib/python/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py","plugin_data":null,"size":17987,"suppressed":[],"version_id":"1.19.1"}